{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCJ2SIR708b6"
   },
   "source": [
    "# 4: Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHIO99Mx08cE"
   },
   "source": [
    "In this exercise, you will practice aggregating and summarizing data with Pandas `groupby` and `pivot_table` and merging/joining datasets using Pandas `concat` and `merge`.\n",
    "\n",
    "You can either print answers directly from your code or write them in the markdown cells below your code. Either way, make sure that your answers are visible and can be easily read in the final notebook you turn in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wVcso_4whNqx"
   },
   "outputs": [],
   "source": [
    "# Here are the needed imports, make sure to run this cell\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZWvwEgw08cF"
   },
   "source": [
    "## Part 1: Summarizing Data\n",
    "In this part we will start by working with the `seaborn` `planets` dataset. Seaborn is a library for data visualization in Python (already included in your Anaconda distribution) to which we will be returning soon. For now, we are just using it for easy access to the `planets` dataset containing information about 1,035 extrasolar planets that have been discovered by Astronomers over the last several years. As an aside, extrasolar planet discovery is an excellent example of how data science can help fuel discovery in the sciences by automating the analysis of large quantities of data, in this case from telescopes. If you're interested (not necessary to complete this assignment), you can read more at https://exoplanets.nasa.gov, from which this dataset was originally drawn.\n",
    "\n",
    "To begin, run the following code to import the dataset into the `planets` DataFrame and preview the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aaiMpA_Q08cF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>number</th>\n",
       "      <th>orbital_period</th>\n",
       "      <th>mass</th>\n",
       "      <th>distance</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>269.300</td>\n",
       "      <td>7.10</td>\n",
       "      <td>77.40</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>874.774</td>\n",
       "      <td>2.21</td>\n",
       "      <td>56.95</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>763.000</td>\n",
       "      <td>2.60</td>\n",
       "      <td>19.84</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>326.030</td>\n",
       "      <td>19.40</td>\n",
       "      <td>110.62</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radial Velocity</td>\n",
       "      <td>1</td>\n",
       "      <td>516.220</td>\n",
       "      <td>10.50</td>\n",
       "      <td>119.47</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            method  number  orbital_period   mass  distance  year\n",
       "0  Radial Velocity       1         269.300   7.10     77.40  2006\n",
       "1  Radial Velocity       1         874.774   2.21     56.95  2008\n",
       "2  Radial Velocity       1         763.000   2.60     19.84  2011\n",
       "3  Radial Velocity       1         326.030  19.40    110.62  2007\n",
       "4  Radial Velocity       1         516.220  10.50    119.47  2009"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run but do not modify this code\n",
    "planets = sns.load_dataset('planets')\n",
    "planets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_djeOIn08cH"
   },
   "source": [
    "### Question 1\n",
    "Use Pandas `groupby` operations to answer the following. You might find the function [Series.idxmax](https://pandas.pydata.org/docs/reference/api/pandas.Series.idxmax.html) useful.\n",
    "\n",
    "1. If you run the code `planets.groupby(\"number\").count()` you will see different values for the different columns. Why is that? Put your answer in \"Answer q1_1\" cell.\n",
    "2. What are the two `method`s that account for the most discoveries? How many discoveries were made with those `method`s? Put your answer in `q1_2`. It should have the type `Series` and the index value is the method and the corresponding data is the number of discoveries. You should be able to create this by indexing into the `GroupBy` object to select the correct rows and columns.\n",
    "3. In which years were more than 100 discoveries made? Put your answer in `q1_3`. It should be the type `numpy.ndarray`.\n",
    "4. Which `method` has found the most distant exoplanets on average (i.e., the `distance` column), and what is that average distance? Put the method name (string) in `q1_4_1` and the average distance (float) in `q1_4_2`.\n",
    "5. Which `method` has found the single most distant exoplanet in the dataset, and what `distance` is that exoplanet? Put the method name (string) in `q1_5_1` and the average distance (float) in `q1_5_2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "d6Cn9WRYqkHM"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_1_manual\n",
    "manual: true\n",
    "points: 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q8WY6BkkwBH"
   },
   "source": [
    "### Answer q1_1\n",
    "\n",
    "There are different values for different columns because the call $\\textbf{count()}$ does not include null values in the count. So if a row had a null value in one column but not the other, the count would only increment in the column without a null value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TGAR_goEuHgm"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "manual: false\n",
    "points:\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 2\n",
    "    - 2\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VFbN54y908cI"
   },
   "outputs": [],
   "source": [
    "# Put your code to answer the question here\n",
    "# Feel free to add additional cells\n",
    "planmeth = planets.groupby(by=['method']).count()\n",
    "q1_2 = planmeth['number'].nlargest(2)\n",
    "\n",
    "planyear = planets.groupby(by=['year']).count()\n",
    "q1_3 = planyear.loc[planyear['number'] > 100].index.values\n",
    "\n",
    "avgmeth = planets.groupby(by=['method']).mean()['distance'].nlargest(1)\n",
    "q1_4_1 = list(avgmeth.index.values)[0]\n",
    "q1_4_2 = avgmeth.loc['Microlensing']\n",
    "\n",
    "maxmeth = planets.groupby(by=['method']).max()['distance'].nlargest(1)\n",
    "q1_5_1 = list(maxmeth.index.values)[0]\n",
    "q1_5_2 = maxmeth.loc['Transit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cy93bd6B08cJ"
   },
   "source": [
    "### Question 2\n",
    "Next we will work with the titanic dataset which contains historical information about the passengers of the cruiseship *Titanic* that sank in the North Atlantic in 1912. Import the dataset and preview the first few rows below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P982OnaX08cK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run but do not modify this code\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sl4N4LN608cK"
   },
   "source": [
    "Use Pandas `pivot_table`s to answer the following.\n",
    "\n",
    "1. Create a DataFrame with the average fare paid by passengers grouped by each combination of `sex` and `class`. Put the result in `q2_1`, the column should be `class` and index should be `sex`.\n",
    "\n",
    "2. Create a DataFrame with the number of passengers grouped by each combination of `class` and `embark_town`. Put the result in `q2_2`, the column should be `embark_town` and index should be `class`.\n",
    "\n",
    "3. Create a DataFrame with the fraction of passengers who survived (i.e., `survived==1`) grouped by each combination of `sex`, `class`, and `embark_town`. Put the result in `q2_3`, the column should be `embark_town` and indices should be `sex` and `class`.\n",
    "  1. For example, if there are four individuals of a given `sex`, `class`, and `embark_town`, and three of the four survived, the value for that combination would be `0.75`.\n",
    "\n",
    "4. Create a DataFrame with the average `age` and the total `fare` paid by passengers grouped by each combination of `class` and `sex`. `age` should be first and `fare` second. Put the result in `q2_4`, the column should be sex (for average `age` and the total `fare` respectively) and index should be class.\n",
    "  1. For example, if there were just 2 passengers with `class==first` and `sex==male` aged `20` and `30` and having paid `fare`s of `50` and `70` each, then the average age of that combination would be `25` and the total `fare` paid would be `120`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "357Grm-z08cL"
   },
   "outputs": [],
   "source": [
    "# Put your code to answer the question here\n",
    "# Feel free to add additional cells, especially \n",
    "# for displaying tables\n",
    "q2_1 = titanic.groupby(['sex', 'class'])['fare'].aggregate('mean').unstack()\n",
    "q2_2 = titanic.groupby(['class', 'embark_town'])['embark_town'].aggregate('count').unstack()\n",
    "q2_3 = titanic.groupby(['sex','class', 'embark_town'])['survived'].aggregate('mean').unstack()\n",
    "q2_4 = titanic.pivot_table(index='class', columns='sex',\n",
    "                    aggfunc={'age':'mean', 'fare':sum})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqrldqBB08cN"
   },
   "source": [
    "## Part 2: Merging Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixKunxtw08cO"
   },
   "source": [
    "We begin by studying four tips files included with this practice: `tips_Thur.csv`, `tips_Fri.csv`, `tips_Sat.csv`, and `tips_Sun.csv`. Each contains information about tips received by servers at a restaurant on the particular days of the week denoted by the file names (Thur for Thursday, Fri for Friday, Sat for Saturday, and Sun for Sunday). Below, we import and preview one of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VkGZ66OI08cO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.20</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.76</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.29</td>\n",
       "      <td>2.71</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.44</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.66</td>\n",
       "      <td>3.40</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip   sex smoker   time  size\n",
       "0       27.20  4.00  Male     No  Lunch     4\n",
       "1       22.76  3.00  Male     No  Lunch     2\n",
       "2       17.29  2.71  Male     No  Lunch     2\n",
       "3       19.44  3.00  Male    Yes  Lunch     2\n",
       "4       16.66  3.40  Male     No  Lunch     2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run but do not modify this code\n",
    "Thur = pd.read_csv(\"tips_Thur.csv\")\n",
    "Thur.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUuVxONs08cP"
   },
   "source": [
    "### Question 3\n",
    "Answer the following questions using the four tips datasets. You will need to combine (using Pandas `concat`) the datasets to answer some of the questions. Furthermore, some of the questions will require information about the day, which is only contained in the file names (though you are welcome to add additional columns to the datasets if you wish).  \n",
    "\n",
    "1. What is the average overall `total_bill` including data from all four days? Put your answer in `q3_1` (float).\n",
    "2. For each of the four days, what is the average `tip` for that day? Put your answer in `q3_2`. It should have the type `Series` and the index value is the day ('Thur', 'Fri', etc.) and the corresponding data is the average tip for that day. You should be able to create this by column indexing the `GroupBy` object.\n",
    "3. Create a pivot table that shows the average ratio of `tip` to `total_bill` (e.g., if a `tip` is `4` and the `total_bill` is `20`, then the ratio would be `0.2`) grouped by `sex` and day. Put the resulting DataFrame in `q3_3`, the column should be day and index should be sex. You may want to use Pandas `pivot_table` to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EpUP5-1G08cQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day          Fri       Sat       Sun      Thur\n",
      "sex                                           \n",
      "Female  0.199388  0.156470  0.181569  0.157525\n",
      "Male    0.143385  0.151577  0.162344  0.165276\n"
     ]
    }
   ],
   "source": [
    "# Put your code to answer the question here\n",
    "# Feel free to add additional cells, especially \n",
    "Fri = pd.read_csv(\"tips_Fri.csv\")\n",
    "Sat = pd.read_csv(\"tips_Sat.csv\")\n",
    "Sun = pd.read_csv(\"tips_Sun.csv\")\n",
    "days = [Thur, Fri, Sat, Sun]\n",
    "\n",
    "q3_1 = sum([day['total_bill'].sum() for day in days])/sum([len(day['total_bill']) for day in days])\n",
    "\n",
    "Fri['day'] = 'Fri'\n",
    "Thur['day'] = 'Thur'\n",
    "Sat['day'] = 'Sat'\n",
    "Sun['day'] = 'Sun'\n",
    "superDF = pd.concat(days)\n",
    "\n",
    "q3_2 = superDF.groupby(['day'])['tip'].aggregate('mean')\n",
    "\n",
    "finDF = superDF\n",
    "finDF['tip'] = finDF['tip']/finDF['total_bill']\n",
    "q3_3 = finDF.pivot_table(values = 'tip', index='sex', columns='day',\n",
    "                    aggfunc='mean')\n",
    "print(q3_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeN7i11X08cR"
   },
   "source": [
    "### Question 4\n",
    "In this question we will work with movie rating data in three different tables/dataframes. You will need to `merge` information from the different tables to answer the questions below. First we import and preview the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LQsG9To508cR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age sex  occupation\n",
       "0        1   24   M  technician\n",
       "1        2   53   F       other\n",
       "2        3   23   M      writer\n",
       "3        4   24   M  technician\n",
       "4        5   33   F       other"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run but do not modify this code\n",
    "users = pd.read_csv(\"users.csv\")\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XtMUVxbp08cR"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0      196       242       3\n",
       "1      186       302       3\n",
       "2       22       377       1\n",
       "3      244        51       2\n",
       "4      166       346       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run but do not modify this code\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uikCbI2C08cS"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id        movie_title\n",
       "0         1   Toy Story (1995)\n",
       "1         2   GoldenEye (1995)\n",
       "2         3  Four Rooms (1995)\n",
       "3         4  Get Shorty (1995)\n",
       "4         5     Copycat (1995)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run but do not modify this code\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cS7eaeiT08cS"
   },
   "source": [
    "Answer the following. \n",
    "\n",
    "1. How many movies have been rated at least 100 times? Put the answer in `q4_1` (numpy.int64 or int).\n",
    "2. Which five users have given the highest average ratings? List their `user_id`s and their average `rating`s. Put the answer in `q4_2`. It should have the type `Series` and the index value is the user_id and the corresponding data is the average rating for that user.\n",
    "3. Create a pivot table that displays average `rating`s grouped by `sex` and `occupation`. Put the answer table in `q4_3`, the column should be sex and index should be occupation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>Three Colors: White (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>educator</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>Three Colors: White (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>Three Colors: White (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>27</td>\n",
       "      <td>M</td>\n",
       "      <td>programmer</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>Three Colors: White (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>49</td>\n",
       "      <td>M</td>\n",
       "      <td>educator</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>Three Colors: White (1994)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age sex  occupation  movie_id  rating                 movie_title\n",
       "0        1   24   M  technician        61       4  Three Colors: White (1994)\n",
       "1       13   47   M    educator        61       4  Three Colors: White (1994)\n",
       "2       18   35   F       other        61       4  Three Colors: White (1994)\n",
       "3       58   27   M  programmer        61       5  Three Colors: White (1994)\n",
       "4       59   49   M    educator        61       4  Three Colors: White (1994)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make master table\n",
    "df = pd.merge(users, ratings)\n",
    "df1 = pd.merge(df, movies)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-TYa1Nb_08cT"
   },
   "outputs": [],
   "source": [
    "# Put your code to answer the question here\n",
    "# Feel free to add additional cells\n",
    "movId = df1.groupby(by=[\"movie_id\"]).count()\n",
    "q4_1 = len(movId.loc[movId['user_id'] > 99])\n",
    "\n",
    "avgR = df1.groupby(by=['user_id']).mean()['rating']\n",
    "q4_2 = avgR.nlargest(5)\n",
    "\n",
    "q4_3 = df1.pivot_table(values = 'rating', index = 'occupation', columns = 'sex', aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fa276yCa08cU"
   },
   "source": [
    "### Question 5\n",
    "We will work with the `restaurants_a.csv` and `restaurants_b.csv` datasets for this question. Each contain five columns: `id` (a numeric index serving as a unique id, not correlated across the datasets), `name` (of the restaurant), `address` (the street address), `city`, and `type` (the type of restaurant). First we import and preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PsCGxWOb08cU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>belvedere  the</td>\n",
       "      <td>9882 little santa monica blvd.</td>\n",
       "      <td>beverly hills</td>\n",
       "      <td>pacific new wave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>triangolo</td>\n",
       "      <td>345 e. 83rd st.</td>\n",
       "      <td>new york</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>broadway deli</td>\n",
       "      <td>3rd st. promenade</td>\n",
       "      <td>santa monica</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>lettuce souprise you (at)</td>\n",
       "      <td>3525 mall blvd.</td>\n",
       "      <td>duluth</td>\n",
       "      <td>cafeterias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>otabe</td>\n",
       "      <td>68 e. 56th st.</td>\n",
       "      <td>new york</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>655</td>\n",
       "      <td>tavern on the green</td>\n",
       "      <td>in central park at 67th st.</td>\n",
       "      <td>new york</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>661</td>\n",
       "      <td>cafe des artistes</td>\n",
       "      <td>1 w. 67th st.</td>\n",
       "      <td>new york city</td>\n",
       "      <td>french (classic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>756</td>\n",
       "      <td>park avenue cafe (new york city)</td>\n",
       "      <td>100 e. 63rd st.</td>\n",
       "      <td>new york city</td>\n",
       "      <td>american (new)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>758</td>\n",
       "      <td>brasserie le coze</td>\n",
       "      <td>3393 peachtree rd.  lenox square mall  near ne...</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>french</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>836</td>\n",
       "      <td>cafe lalo</td>\n",
       "      <td>201 w. 83rd st.</td>\n",
       "      <td>new york city</td>\n",
       "      <td>coffeehouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>186 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                              name  \\\n",
       "0      0                    belvedere  the   \n",
       "1      1                         triangolo   \n",
       "2      2                     broadway deli   \n",
       "3      3         lettuce souprise you (at)   \n",
       "4      4                             otabe   \n",
       "..   ...                               ...   \n",
       "181  655               tavern on the green   \n",
       "182  661                 cafe des artistes   \n",
       "183  756  park avenue cafe (new york city)   \n",
       "184  758                 brasserie le coze   \n",
       "185  836                         cafe lalo   \n",
       "\n",
       "                                               address           city  \\\n",
       "0                       9882 little santa monica blvd.  beverly hills   \n",
       "1                                      345 e. 83rd st.       new york   \n",
       "2                                    3rd st. promenade   santa monica   \n",
       "3                                      3525 mall blvd.         duluth   \n",
       "4                                       68 e. 56th st.       new york   \n",
       "..                                                 ...            ...   \n",
       "181                        in central park at 67th st.       new york   \n",
       "182                                      1 w. 67th st.  new york city   \n",
       "183                                    100 e. 63rd st.  new york city   \n",
       "184  3393 peachtree rd.  lenox square mall  near ne...        atlanta   \n",
       "185                                    201 w. 83rd st.  new york city   \n",
       "\n",
       "                 type  \n",
       "0    pacific new wave  \n",
       "1             italian  \n",
       "2            american  \n",
       "3          cafeterias  \n",
       "4               asian  \n",
       "..                ...  \n",
       "181          american  \n",
       "182  french (classic)  \n",
       "183    american (new)  \n",
       "184            french  \n",
       "185      coffeehouses  \n",
       "\n",
       "[186 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run but do not modify this code\n",
    "df_a = pd.read_csv(\"restaurants_A.csv\")\n",
    "df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vI3kI6FS08cV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>indigo coastal grill</td>\n",
       "      <td>1397 n. highland ave.</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>eclectic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>aqua</td>\n",
       "      <td>252 california st.</td>\n",
       "      <td>san francisco</td>\n",
       "      <td>american (new)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>boulevard</td>\n",
       "      <td>1 mission st.</td>\n",
       "      <td>san francisco</td>\n",
       "      <td>american (new)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>khan toke thai house</td>\n",
       "      <td>5937 geary blvd.</td>\n",
       "      <td>san francisco</td>\n",
       "      <td>thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151</td>\n",
       "      <td>bacchanalia</td>\n",
       "      <td>3125 piedmont rd.  near peachtree rd.</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>801</td>\n",
       "      <td>cafe des artistes</td>\n",
       "      <td>1 w. 67th st.</td>\n",
       "      <td>new york</td>\n",
       "      <td>continental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>828</td>\n",
       "      <td>uncle nick's</td>\n",
       "      <td>747 ninth ave.</td>\n",
       "      <td>new york city</td>\n",
       "      <td>greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>851</td>\n",
       "      <td>brasserie le coze</td>\n",
       "      <td>3393 peachtree rd.</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>french bistro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>852</td>\n",
       "      <td>postrio</td>\n",
       "      <td>545 post st.</td>\n",
       "      <td>san francisco</td>\n",
       "      <td>californian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>853</td>\n",
       "      <td>cafe lalo</td>\n",
       "      <td>201 w. 83rd st.</td>\n",
       "      <td>new york</td>\n",
       "      <td>coffee bar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                  name                                address  \\\n",
       "0     22  indigo coastal grill                  1397 n. highland ave.   \n",
       "1     54                  aqua                     252 california st.   \n",
       "2     89             boulevard                          1 mission st.   \n",
       "3    150  khan toke thai house                       5937 geary blvd.   \n",
       "4    151           bacchanalia  3125 piedmont rd.  near peachtree rd.   \n",
       "..   ...                   ...                                    ...   \n",
       "176  801     cafe des artistes                          1 w. 67th st.   \n",
       "177  828          uncle nick's                         747 ninth ave.   \n",
       "178  851     brasserie le coze                     3393 peachtree rd.   \n",
       "179  852               postrio                           545 post st.   \n",
       "180  853             cafe lalo                        201 w. 83rd st.   \n",
       "\n",
       "              city            type  \n",
       "0          atlanta        eclectic  \n",
       "1    san francisco  american (new)  \n",
       "2    san francisco  american (new)  \n",
       "3    san francisco            thai  \n",
       "4          atlanta   international  \n",
       "..             ...             ...  \n",
       "176       new york     continental  \n",
       "177  new york city           greek  \n",
       "178        atlanta   french bistro  \n",
       "179  san francisco     californian  \n",
       "180       new york      coffee bar  \n",
       "\n",
       "[181 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run but do not modify this code\n",
    "df_b = pd.read_csv(\"restaurants_B.csv\")\n",
    "df_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiziibDD08cV"
   },
   "source": [
    "Some, but not all, of the restaurants in the two datasets are actually the same. In this question, we would like to consider the problem of merging the datasets. Unfortunately, the `id`s do not correspond between the datasets, so there is no obvious primary key to merge on. In this question, you will explore a fuzzy matching to link the records between the two datasets. You will be asked to use the `edit_dist` function, but you do not need to implement it. An implementation is provided for you in `edit_distance.py`, and you can simply import the function below. It takes two strings as input and returns the edit distance between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FhTMNFaF08cV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Run but do not modify this code\n",
    "from edit_distance import edit_dist\n",
    "\n",
    "# Example of using the edit_dist function\n",
    "print(edit_dist(\"hello\", \"hallo!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdAmrH-208cW"
   },
   "source": [
    "Answer the following.\n",
    "\n",
    "1. First, try to perform an inner merge (the default for Pandas `merge`) on the two datasets on the `name` column. How many rows are in the resulting merged dataset? Put your answer in `q5_1`. Why is this value much smaller than the sizes of `df_a` and `df_b`? Put your answer in the \"Answer q5\" cell.\n",
    "2. Next, try to perform an inner merge on the two datasets on the `city` column. How many rows are in the resulting merged dataset? Put your answer in `q5_2`. Why is this value much larger than the sizes of `df_a` and `df_b`? Put your answer in the \"Answer q5\" cell.\n",
    "3. Find the names of all pairs of records (one from `df_a` and the other from `df_b`) such that the two names have edit distance of 1 or 2 (note that if two strings have edit distance 0, they are exactly the same; you do not need to log these). It is fine to use `for` loops to solve this and your code may take a second or two to run. Put your answer in `q5_3`, it should be a set of tuples (name_a, name_b).\n",
    "4. Among the names you identified in step 3, which pairs do you think are actually mispellings, and which do you think might actually be different restaurants? Explain your answer using information from other columns beside `name`. Feel free to add additional cells to write code. Put your answer in the \"Answer q5\" cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yn_DBO_L08cW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "4887\n",
      "{('uncle nicks', \"uncle nick's\"), ('drago', 'spago'), ('boulavard', 'boulevard'), ('mesa grill', 'sea grill'), ('felidia', 'filidia'), ('march', 'marichu'), ('indigo coast grill', 'indigo coastal grill'), (\"l'orangerie\", 'l orangerie')}\n"
     ]
    }
   ],
   "source": [
    "# Put your code to answer the question here\n",
    "# Feel free to add additional cells\n",
    "q5_1 = len(pd.merge(df_a, df_b, on = 'name'))\n",
    "print(q5_1)\n",
    "q5_2 = len(pd.merge(df_a, df_b, on = 'city'))\n",
    "print(q5_2)\n",
    "\n",
    "aName = set(df_a['name'].tolist())\n",
    "bName = set(df_b['name'].tolist())\n",
    "opt = set()\n",
    "allNames = []\n",
    "for i in aName:\n",
    "    for j in bName:\n",
    "        dist = edit_dist(i,j)\n",
    "        if dist == 1 or dist == 2:\n",
    "            opt.add((i,j))\n",
    "            allNames.append(i)\n",
    "            allNames.append(j)\n",
    "            \n",
    "q5_3 = opt\n",
    "print(q5_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      name          city     type\n",
      "121  drago  santa monica  italian\n",
      "     name         city         type\n",
      "75  spago  los angeles  californian\n",
      "           name           city          type\n",
      "174  mesa grill  new york city  southwestern\n",
      "         name      city     type\n",
      "84  sea grill  new york  seafood\n",
      "            name      city           type\n",
      "180  uncle nicks  new york  mediterranean\n",
      "             name           city   type\n",
      "177  uncle nick's  new york city  greek\n",
      "         name           city      type\n",
      "60  boulavard  san francisco  american\n",
      "        name           city            type\n",
      "2  boulevard  san francisco  american (new)\n",
      "           name          city              type\n",
      "11  l'orangerie  w. hollywood  french (classic)\n",
      "            name         city    type\n",
      "137  l orangerie  los angeles  french\n",
      "        name           city     type\n",
      "161  felidia  new york city  italian\n",
      "        name      city     type\n",
      "114  filidia  new york  italian\n",
      "                  name     city       type\n",
      "12  indigo coast grill  atlanta  caribbean\n",
      "                   name     city      type\n",
      "0  indigo coastal grill  atlanta  eclectic\n",
      "      name           city            type\n",
      "163  march  new york city  american (new)\n",
      "       name      city    type\n",
      "18  marichu  new york  french\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(allNames)):\n",
    "    if i%2 == 0:\n",
    "        print(df_a.loc[df_a['name'] == allNames[i]][['name', 'city', 'type']])\n",
    "    else:\n",
    "        print(df_b.loc[df_b['name'] == allNames[i]][['name', 'city', 'type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FdDREzDPidsS"
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_manual\n",
    "manual: true\n",
    "points: 8\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7Lrya0LkwBQ"
   },
   "source": [
    "### Answer q5\n",
    "\n",
    "##### Q5 P1\n",
    "\n",
    "This is much smaller than the sizes of df_a and df_b because the merge only outputs one row when df_a and df_b both contained restaurants with the same name. Basically this is the number of duplicate restaurant entries (or just two restaurants who happen to have the exact same name) across the two tables. This is a one-to-one mapping (assuming no two restaurants in a table have the same name). \n",
    "\n",
    "##### Q5 P2\n",
    "\n",
    "The length of this merge is much larger than the lengths of df_a and df_b because many restaurants can exist in the same city, so we have a many-to-one mapping for a lot of these restaurants. For example, if restaurant A is in city 'new york,' there will be rows matching it to every restaurant in df_b that are also in city 'new york.'\n",
    "\n",
    "##### Q5 P4\n",
    "\n",
    "I think that uncle nicks vs uncle nick's is a misspelling, because both are mediterranean/greek restaurants in NYC so it is likely they are both owned by the same people. I think drago and spago are actually different restaurants because they are in different parts of California and drago is italian while spago is californian. I think that felidia vs filidia is a misspelling, because both are italian restaurants in nyc. I think march and marichu are different restaurants because even though they are in the same city, one is french and one is american. I think l'orangerie and l orangerie are the same, because they are both french restaurants in california and one is just missing the appostrophe. Mesa grill and sea grill are different restaurants because one is seafood and one is southwestern food. I think boulavard vs boulevard is a misspelling because both are american food in san fracisco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "practice4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
